{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Integrating TigerGraph with NVIDIA Graph Libraries","text":"<p>This website is for software developers that want to integrate TigerGraph with NVIDIA graph libraries such as CuGraph, RAPIDS and WholeGraph.</p> <p>This is a work in progess.</p> <p>Dan McCreary LinkedIn</p>"},{"location":"about/","title":"About the TigerGraph NVIDIA Partnership","text":"<p>TigerGraph has a long history of working with graph evangilists within NVIDIA. Although GPUs were not designed to do graph analytics, by using  sparse matrix represnetations we can use GPUs to accelerate some graph algorithms.</p> <p>NVIDIA GPUs also offer the ability to train Graph Neural Networks to perform tasks such as link prediction, recommendation and anomolyy detection.</p> <p>This guide is designed for developers that are building solutions that integrate NVIDIA hardware into TigerGraph.</p>"},{"location":"contact/","title":"Contacts","text":""},{"location":"contact/#tigergraph","title":"TigerGraph","text":"<p>Dan McCreary LinkedIn Victor Lee</p>"},{"location":"contact/#nvidia","title":"NVIDIA","text":"<p>Chuck Hastings Brad Rees</p>"},{"location":"glossary/","title":"TigerGraph CuGraph Glossary of Terms","text":""},{"location":"glossary/#adjency-matrix","title":"Adjency Matrix","text":"<p>A square matrix used to represent a graph, where each element at position (i, j) indicates the presence (typically with a 1) or absence (typically with a 0) of an edge between the vertices i and j. For undirected graphs, the matrix is symmetric; for directed graphs, the matrix reflects the direction of edges.</p>"},{"location":"glossary/#batch","title":"Batch","text":""},{"location":"glossary/#compressed-row-storage-crs","title":"Compressed Row Storage (CRS)","text":"<p>A space-efficient format used to store sparse matrices. In CRS, only the non-zero elements of the matrix are stored, along with two additional arrays: one for the column indices of the non-zero elements and another to mark the starting index of each row in the data array. This format reduces memory usage and enables faster access to non-zero elements, especially when performing matrix-vector multiplication.</p>"},{"location":"glossary/#cugraph","title":"CuGraph","text":"<p>A collection of GPU-accelerated graph algorithms and services that run on NVIDIA GPUs.</p> <p>You can think of CuGraph as a version of NVIDIA CUDA C libraries but focused on working on graph data.</p>"},{"location":"glossary/#edge-classification","title":"Edge Classification","text":""},{"location":"glossary/#graph-neural-network-gnn","title":"Graph Neural Network (GNN)","text":"<p>A type of neural network specifically designed to operate on graph-structured data. It learns representations of nodes, edges, or entire graphs by iteratively aggregating and transforming information from a node's local neighborhood. GNNs are capable of capturing both the features of individual nodes and the relationships between them, making them well-suited for tasks like node classification, link prediction, and graph classification in applications such as social networks, molecular biology, and recommendation systems.</p>"},{"location":"glossary/#link-prediction","title":"Link Prediction","text":"<p>The process of using machine learning to predict a new or missing link from an existing graph.</p> <p>Link prediction is of the key use cases for GNNs,  Link prediction is also used in many areas of process mining including predicting social network relationships, customer purchases and recommendations.</p>"},{"location":"glossary/#nvidia-collective-communications-library-nccl","title":"NVIDIA Collective Communications Library (NCCL)","text":"<p>NCCL (pronounced \"nickel\") is an ID assigned to a process on one of the GPUs in a cluster.</p> <ul> <li>NCCL on the NVIDIA Developer Website</li> <li>NCCL Current Docs</li> <li>NCCL Archive Docs</li> </ul>"},{"location":"glossary/#nccl-id","title":"NCCL ID","text":"<p>An object created by the NCCL that which is used by all processes and threads to synchronize and understand they are part of the same communicator.</p> <p>Before using the NCLL software, you need to first create a unique object ID by calling the ncclGetUniqueId function.</p> <p>The ncclGetUniqueId function returns an ID which has to be broadcast to all participating threads and processes using any CPU communication system, for example, passing the ID pointer to multiple threads, or broadcasting it to other processes using MPI or another parallel environment using, for example, sockets.</p> <p>NVIDA Deeplearning Web Site Archive</p>"},{"location":"glossary/#pagerank","title":"PageRank","text":""},{"location":"glossary/#pytorch-geometic","title":"PyTorch Geometic","text":""},{"location":"glossary/#rapids","title":"RAPIDS","text":"<p>RAPIDS is NVIDIA developed Open Source software packatge designed to enable data scientists staff to more easily use NVIDIA GPUs.</p> <p>RAPIDS has connectors that work with popular Python data science libraries such as Pandas, Scikit-Learn and NetworkX.</p> <p>RAPIDS website</p>"},{"location":"glossary/#sampling","title":"Sampling","text":"<p>The process of selecting a subset of nodes and their corresponding neighbors from a large graph to efficiently train the GNN.</p> <p>Since processing the entire graph can be computationally expensive, sampling methods\u2014such as node sampling, edge sampling, or neighborhood sampling\u2014reduce the graph's size while preserving key structural properties. This allows the GNN to learn from local node interactions and aggregate information without needing to process the full graph at each training step.</p>"},{"location":"glossary/#seeds","title":"Seeds","text":"<p>The initial set of nodes or edges selected as the starting point for the sampling process. From these seed nodes, their neighbors are sampled in successive steps to construct a subgraph or a local neighborhood.</p> <p>The choice of seed nodes influences which part of the graph is explored, and they are typically chosen based on specific criteria such as random selection, high centrality, or other graph metrics. Seeds help to reduce the computational cost of processing large graphs by focusing on smaller, relevant sections.</p>"},{"location":"glossary/#sparse-matrix","title":"Sparse Matrix","text":"<p>A matrix in which most of the elements are zero.</p> <p>It is commonly used in data structures and algorithms to efficiently represent large datasets with few non-zero elements, reducing memory usage and computational complexity compared to dense matrices. Sparse matrices are often stored using specialized formats like compressed row storage or coordinate format.</p> <p>Most enterprise knowledge graphs contain billions of verticies but each vertex only has around five releationships. Useing an adjency matrix</p> <p>Wikipedia Page on Sparse Matrix</p>"},{"location":"glossary/#user-defined-function","title":"User Defined Function","text":"<p>A function written by a specific user that adds new functionality to TigerGraph.  Unlike GSQL functions, User Defined Functions (UDFs) must be written in C/C++.</p> <p>UDFs are the method that TigerGraph calls the CuGraph interfaces.</p>"},{"location":"glossary/#wholegraph","title":"WholeGraph","text":"<p>WholeGraph is a software system that allows users to partion a large group on multiple GPUs.</p> <p>WholeGraph was developed to help train large-scale Graph Neural Networks(GNN). WholeGraph provides underlying storage structure called WholeMemory. WholeMemory is a Tensor like storage and provide multi-GPU support. It is optimized for NVLink systems like DGX A100 servers. By working together with cuGraph, cuGraph-Ops, cuGraph-DGL, cuGraph-PyG, and upstream DGL and PyG, it will be easy to build GNN applications.</p> <p>WholeGraph GitHub Repo</p>"},{"location":"glossary/#worker","title":"Worker","text":""},{"location":"references/","title":"TigerGraph CuGraph Integration References","text":"<p>CuGraph GitHub Repo</p>"}]}